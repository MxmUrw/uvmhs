module UVMHSContrib.Lang.SExp where

import UVMHS

lexer ‚à∑ Lexer CharClass ‚ÑÇ TokenClassBasic ‚Ñï64 TokenBasic
lexer = lexerBasic (list ["(",")"]) (list ["KEY"]) (list ["PRIM"]) (list ["+"])

testSExpTokenizerSuccess ‚à∑ IO ()
testSExpTokenizerSuccess = 
  tokenizeIOMain lexer "" $ prepTokens $ tokens "((-1-2-1.42(\"astringwith\\\\stuff\\n\" ( "

testSExpTokenizerFailure1 ‚à∑ IO ()
testSExpTokenizerFailure1 =
  tokenizeIOMain lexer "" $ prepTokens $ tokens "((foo-1and0.01+bar"

testSExpTokenizerFailure2 ‚à∑ IO ()
testSExpTokenizerFailure2 =
  tokenizeIOMain lexer "" $ prepTokens $ tokens "()foo-1\"astring\\badescape\""

data Lit =
    IntegerL ‚Ñ§
  | DoubleL ùîª
  | StringL ùïä
makePrettySum ''Lit

data Atom =
    LitA Lit
  | NameA ùïä
  | KeyA
  | PrimA
  | PlusA
makePrettySum ''Atom

type Exp = Annotated FullContext ExpPre
data ExpPre =
    AtomE Atom
  | ListE (ùêø Exp)
makePrettySum ''ExpPre

------------
-- Parser --
------------

cpLit ‚à∑ CParser TokenBasic Lit
cpLit = concat
  [ IntegerL ^$ cpShaped $ view integerTBasicL
  , DoubleL ^$ cpShaped $ view doubleTBasicL
  , StringL ^$ cpShaped $ view stringTBasicL
  ]

cpAtom ‚à∑ CParser TokenBasic Atom
cpAtom = cpNewContext "atom" $ concat
  [ cpErr "literal" $ LitA ^$ cpLit
  , cpErr "name" $ NameA ^$ cpShaped $ view nameTBasicL
  , cpErr "keyword" $ const KeyA ^$ cpSyntax "KEY"
  , cpErr "primitive" $ const PrimA ^$ cpSyntax "PRIM"
  , cpErr "‚Äú+‚Äù" $ const PlusA ^$ cpSyntax "+"
  ]

cpExp ‚à∑ CParser TokenBasic Exp
cpExp = cpNewContext "expression" $ cpWithContextRendered $ concat
  [ AtomE ^$ cpAtom
  , ListE ^$ cpList
  ]

cpList ‚à∑ CParser TokenBasic (ùêø Exp)
cpList = cpNewContext "list" $ do
  cpErr "‚Äú(‚Äù" $ void $ cpSyntax "("
  es ‚Üê cpMany cpExp
  cpErr "‚Äú)‚Äù" $ void $ cpSyntax ")"
  return es

testSExpParserSuccess ‚à∑ IO ()
testSExpParserSuccess = do
  tokenizeIOMain lexer "" input
  toks ‚Üê prepTokens ^$ tokenizeIO lexer "" input
  parseIOMain cpExp "" $ stream toks
  where
    input ‚à∑ ùïç (ParserToken ‚ÑÇ)
    input = prepTokens $ tokens " ( PRIM KEY x + y  {- yo -} ( -1-2)  0.0 \n x   y   z \n abc -12  )  "

testSExpParserFailure1 ‚à∑ IO ()
testSExpParserFailure1 = do
  tokenizeIOMain lexer "" input
  toks ‚Üê prepTokens ^$ tokenizeIO lexer "" input
  parseIOMain cpExp "" $ stream toks
  where
    input ‚à∑ ùïç (ParserToken ‚ÑÇ)
    input = prepTokens $ tokens " (( PRIM KEY x + y  {- yo -} ( -1-2)  0.0 \n x   y   z \n abc -12 )  "

testSExpParserFailure2 ‚à∑ IO ()
testSExpParserFailure2 = do
  tokenizeIOMain lexer "" input
  toks ‚Üê prepTokens ^$ tokenizeIO lexer "" input
  parseIOMain cpExp "" $ stream toks
  where
    input ‚à∑ ùïç (ParserToken ‚ÑÇ)
    input = prepTokens $ tokens " )( PRIM KEY x + y  {- yo -} ( -1-2)  0.0 \n x   y   z \n abc -12 )  "

testSExpParserFailure3 ‚à∑ IO ()
testSExpParserFailure3 = do
  tokenizeIOMain lexer "" input
  toks ‚Üê prepTokens ^$ tokenizeIO lexer "" input
  parseIOMain cpExp "" $ stream toks
  where
    input ‚à∑ ùïç (ParserToken ‚ÑÇ)
    input = prepTokens $ tokens " ( PRIM KEY x + y  {- yo -} ( -1-2)  0.0 \n x   y   z \n abc -12 )(  "
